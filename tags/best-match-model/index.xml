<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>best match model on Jeffery's Blog</title><link>https://blog.jefferyho.cc/tags/best-match-model/</link><description>Recent content in best match model on Jeffery's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Thu, 05 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.jefferyho.cc/tags/best-match-model/index.xml" rel="self" type="application/rss+xml"/><item><title>Best Match Model 25 (BM25)</title><link>https://blog.jefferyho.cc/p/ir-homework2/</link><pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate><guid>https://blog.jefferyho.cc/p/ir-homework2/</guid><description>Kaggle competitions 2020: Information Retrieval and Applications
Homework2: Best Match Models
https://www.kaggle.com/c/2020-information-retrieval-and-applications-hw2
Github code https://github.com/chiachun2491/NTUST_IR/tree/master/homework2
Homework report 使用的 tool Python, Jupyter, numpy, dataframe, datetime
資料前處理 將 doc_list.txt 和 query_list.txt 讀檔進來後，之後將每個 doc 和 query 都使用 split() 儲存起來。 跟上次 Vector Space Model 的作業一樣，在生成 Lexicon 時只看 query_list 切完的所有詞並放到 set 中來生成，這樣能把 Lexicon 的維度從 59680 降到僅 123 而已。 跟上次作業相同先將 document term-frequency, query term-frequency, inverse document frequency 先算好供後面算 BM25 term weight 使用。 BM25 模型參數調整 BM25 term weight 公式： $$sim_{BM25}\left (d_{j}, q \right ) \equiv \sum_{w_{j}\in \left ( d_{j} \cap q \right )}^{} IDF(w_{j}) \times \frac{ \left ( K_{1} + 1 \right ) \times tf_{i,j}}{K_{1} [\left ( 1 - b \right ) + b \times \frac{len\left ( d_{j} \right )}{avg_{doclen}}] + tf_{i,j}} \times \frac{\left ( K_{3} + 1 \right ) \times tf_{i,q}}{ K_{3} + tf_{i,q}}$$</description></item></channel></rss>