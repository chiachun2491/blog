<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>plsa on Jeffery's Blog</title><link>https://blog.jeffery.tk/tags/plsa/</link><description>Recent content in plsa on Jeffery's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Thu, 26 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.jeffery.tk/tags/plsa/index.xml" rel="self" type="application/rss+xml"/><item><title>PLSA</title><link>https://blog.jeffery.tk/p/ir-homework4/</link><pubDate>Thu, 26 Nov 2020 00:00:00 +0000</pubDate><guid>https://blog.jeffery.tk/p/ir-homework4/</guid><description>Kaggle competitions 2020: Information Retrieval and Applications
Homework 4: PLSA
https://www.kaggle.com/c/2020-information-retrieval-and-applications-hw4-v2
Github code https://github.com/chiachun2491/NTUST_IR/tree/master/homework4
Homework report 使用的 tool Python, Jupyter, numpy, pandas, collections.Counter, scipy.sparse, numba.jit, datetime
資料前處理 將 doc_list.txt, query_list.txt 讀檔進來後，之後將每個 doc 使用 collections.Counter 儲存到 dict，每個 query 都使用 split() 儲存到 dict。 這次 Lexicon 的生成方式跟之前不一樣，之前在生成 Lexicon 時只看 query_list 的所有單詞，這次先將 doc 和 query 出現過的詞加入 Lexicon 並先計算好 document length, c(w, d), P(w|d), P(w|BG) 先算好供後面算 term weight 使用。為了加速運算，決定還是減少單字的數量，只取出現次數遞減取前 10000 個單字，再把 query 的字也加進去。 PLSA 模型參數調整 PLSA term weight 公式：</description></item></channel></rss>