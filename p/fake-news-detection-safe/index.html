<!doctype html><html lang=zh-tw><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="2020 Pacific-Asia Conference on Knowledge Discovery and Data Mining"><title>Similarity-Aware Multi-Modal Fake News Detection</title><link rel=canonical href=https://blog.jefferyho.cc/p/fake-news-detection-safe/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="Similarity-Aware Multi-Modal Fake News Detection"><meta property="og:description" content="2020 Pacific-Asia Conference on Knowledge Discovery and Data Mining"><meta property="og:url" content="https://blog.jefferyho.cc/p/fake-news-detection-safe/"><meta property="og:site_name" content="Jeffery's Blog"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="pakdd"><meta property="article:tag" content="fake news detection"><meta property="article:tag" content="multi-modal analysis"><meta property="article:tag" content="neural networks"><meta property="article:tag" content="representation learning"><meta property="article:published_time" content="2021-06-17T00:00:00+00:00"><meta property="article:modified_time" content="2021-06-17T00:00:00+00:00"><meta property="og:image" content="https://blog.jefferyho.cc/p/fake-news-detection-safe/image-20210715181436622.png"><meta name=twitter:title content="Similarity-Aware Multi-Modal Fake News Detection"><meta name=twitter:description content="2020 Pacific-Asia Conference on Knowledge Discovery and Data Mining"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.jefferyho.cc/p/fake-news-detection-safe/image-20210715181436622.png"><link rel="shortcut icon" href=/favicon.png><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','G-L2WL9D18N6','auto');ga('send','pageview');}</script></head><body class="article-page has-toc"><script>(function(){const colorSchemeKey='StackColorScheme';if(!localStorage.getItem(colorSchemeKey)){localStorage.setItem(colorSchemeKey,"auto");}})();</script><script>(function(){const colorSchemeKey='StackColorScheme';const colorSchemeItem=localStorage.getItem(colorSchemeKey);const supportDarkMode=window.matchMedia('(prefers-color-scheme: dark)').matches===true;if(colorSchemeItem=='dark'||colorSchemeItem==='auto'&&supportDarkMode){document.documentElement.dataset.scheme='dark';}else{document.documentElement.dataset.scheme='light';}})();</script><div class="container main-container flex
extended"><div id=article-toolbar><a href=https://blog.jefferyho.cc/ class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/fake-news-detection-safe/><img src=/p/fake-news-detection-safe/image-20210715181436622_hu1fe59100f806a3b1884406926f185a64_1483991_800x0_resize_box_2.png srcset="/p/fake-news-detection-safe/image-20210715181436622_hu1fe59100f806a3b1884406926f185a64_1483991_800x0_resize_box_2.png 800w, /p/fake-news-detection-safe/image-20210715181436622_hu1fe59100f806a3b1884406926f185a64_1483991_1600x0_resize_box_2.png 1600w" width=800 height=279 loading=lazy alt="Featured image of post Similarity-Aware Multi-Modal Fake News Detection"></a></div><div class=article-details><header class=article-category><a href=/categories/fake-news-detection/>Fake News Detection</a>
<a href=/categories/paper/>Paper</a></header><h2 class=article-title><a href=/p/fake-news-detection-safe/>Similarity-Aware Multi-Modal Fake News Detection</a></h2><h3 class=article-subtitle>2020 Pacific-Asia Conference on Knowledge Discovery and Data Mining</h3><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Jun 17, 2021</time></footer></div></header><section class=article-content><blockquote><p>Zhou, Xinyi & Wu, Jindi & Zafarani, Reza. (2020). SAFE: Similarity-Aware Multi-Modal Fake News Detection.</p></blockquote><h2 id=introduction>Introduction</h2><h3 id=fake-news-detection>Fake News Detection</h3><p>假新聞（故意且可驗證虛假的新聞文章）通常包含文本和視覺的資訊，現有的基於內容的假新聞檢測方法不是只考慮文本信息，就是結合兩種類型的數據而忽略關係（相似性）。
作者認為在判斷假新聞的任務上，理解這種關係（相似性）以預測假新聞的價值有兩個方面。</p><h3 id=relationship-similarity-for-predicting-fake-news>Relationship (similarity) for predicting fake news</h3><p>一些假新聞（或可信度低的新聞）為了吸引公眾注意力，更喜歡使用戲劇性、幽默（滑稽）和誘人的圖像，其內容與新聞文本中的實際內容相去甚遠。</p><p>所以當一篇假新聞文章講述一個帶有虛構場景或陳述的故事時，是很難找到相關的和未經處理的圖像來匹配這些虛構的內容，因此當創作者使用未經處理的圖像來支持非事實的場景或陳述時，假新聞的文本和視覺信息之間是存在「<strong>差距</strong>」的。</p><p><figure style=flex-grow:148;flex-basis:357px><a href=/p/fake-news-detection-safe/image-20210715181043959.png data-size=860x578><img src=/p/fake-news-detection-safe/image-20210715181043959.png srcset="/p/fake-news-detection-safe/image-20210715181043959_hu4c74a270de04c870ca3141c64d84d041_79713_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715181043959_hu4c74a270de04c870ca3141c64d84d041_79713_1024x0_resize_box_2.png 1024w" width=860 height=578 loading=lazy alt="Miscaptioned Definition"></a><figcaption>Miscaptioned Definition</figcaption></figure><figure style=flex-grow:97;flex-basis:234px><a href=/p/fake-news-detection-safe/image-20210715181147943.png data-size=860x881><img src=/p/fake-news-detection-safe/image-20210715181147943.png srcset="/p/fake-news-detection-safe/image-20210715181147943_huc99c3a8c78c233b5087b183b206703a5_312664_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715181147943_huc99c3a8c78c233b5087b183b206703a5_312664_1024x0_resize_box_2.png 1024w" width=860 height=881 loading=lazy alt="Examples at https://www.snopes.com/fact-check/rating/miscaptioned/"></a><figcaption>Examples at <a href=https://www.snopes.com/fact-check/rating/miscaptioned/>https://www.snopes.com/fact-check/rating/miscaptioned/</a></figcaption></figure></p><h3 id=usuimilarity-uauware-ufuakueu-news-detection-method-safe><u>S</u>imilarity-<u>A</u>ware <u>F</u>ak<u>E</u> news detection method (SAFE)</h3><p>SAFE 由三個模塊組成：</p><ul><li>多模態（文本和視覺）特徵提取</li><li>模態內（模態獨立）假新聞預測</li><li>跨模態相似度提取</li></ul><p><figure style=flex-grow:286;flex-basis:688px><a href=/p/fake-news-detection-safe/image-20210715181436622.png data-size=3572x1246><img src=/p/fake-news-detection-safe/image-20210715181436622.png srcset="/p/fake-news-detection-safe/image-20210715181436622_hu1fe59100f806a3b1884406926f185a64_1483991_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715181436622_hu1fe59100f806a3b1884406926f185a64_1483991_1024x0_resize_box_2.png 1024w" width=3572 height=1246 loading=lazy alt="SAFE Framework overview"></a><figcaption>SAFE Framework overview</figcaption></figure></p><p>對於每篇新聞文章，會用神經網絡自動獲取其文本和影像的潛在表達式，並且計算出它們之間的相似性後，聯合學習新聞文本和視覺的表達式及相似性來預測假新聞。</p><p>作者所提出的方法主要的目的在識別新聞文章在其文本或圖像上的虛假性，或文本和圖像之間的<strong>不匹配</strong>。</p><h3 id=contributions>Contributions</h3><p>本文是第一個提出藉由觀察新聞文本和視覺信息之間的關係（相似性）在辨識假新聞任務上，文中提出了一種聯合利用多模態（文本和視覺）和之間的相似性來學習新聞文章的表達式並預測假新聞的方法。</p><h2 id=methodology>Methodology</h2><h3 id=problem-definition-and-key-notation>Problem Definition and Key Notation</h3><ul><li>Given a news article $A = {T, V }$ ( $T = $ text information, $V = $ visual information)</li><li>Denote $t,v \in \mathbb{R}^d$ as corresponding representations, $t = M_t(T, \theta_t), v=M_v(V, \theta_v)$</li><li>Let $s = M_s(t, v)$ denote the similarity between $t$ and $v$ , where $s \in [0, 1]$</li><li>Goal: $M_p: (M_t, M_v, M_s) \overset{(\theta_t, \theta_v, \theta_p)}{\longrightarrow} \hat{y} \in [0,1]$, where $\theta_*$ are parameters to be learned<ul><li>Determine whether $A$ is fake news $(\hat{y} = 1)$ or true one $(\hat{y} = 0)$.</li><li>By investigating its textual, visual information, and their relationship.</li></ul></li></ul><h3 id=feature-extraction>Feature Extraction</h3><h4 id=text>Text</h4><p>在新聞文本的部分 SAFE 透過引入額外的全連接層來擴展 Text-CNN 來提取每篇新聞文章的文本特徵。</p><p><figure style=flex-grow:239;flex-basis:574px><a href=/p/fake-news-detection-safe/image-20210715183449938.png data-size=2240x936><img src=/p/fake-news-detection-safe/image-20210715183449938.png srcset="/p/fake-news-detection-safe/image-20210715183449938_hu3b743b299a93eb2ce79b2b73969d8bfe_352725_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715183449938_hu3b743b299a93eb2ce79b2b73969d8bfe_352725_1024x0_resize_box_2.png 1024w" width=2240 height=936 loading=lazy alt=Text-CNN></a><figcaption>Text-CNN</figcaption></figure></p><h4 id=image>Image</h4><p>首先使用預訓練的 image2sentence 模型將新聞內容中的圖像轉換成文字訊息後，同樣使用和處理文字相同的 Text-CNN 來提取特徵。</p><p><figure style=flex-grow:464;flex-basis:1114px><a href=/p/fake-news-detection-safe/image-20210715183859191.png data-size=3324x716><img src=/p/fake-news-detection-safe/image-20210715183859191.png srcset="/p/fake-news-detection-safe/image-20210715183859191_hu9dd449b03ca8584abf1cfb78fd2ec66d_3138806_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715183859191_hu9dd449b03ca8584abf1cfb78fd2ec66d_3138806_1024x0_resize_box_2.png 1024w" width=3324 height=716 loading=lazy alt="image2sentence example (source: https://github.com/nikhilmaram/Show_and_Tell )"></a><figcaption>image2sentence example (source: <a href=https://github.com/nikhilmaram/Show_and_Tell>https://github.com/nikhilmaram/Show_and_Tell</a> )</figcaption></figure></p><p>跟目前的多模態假新聞檢測研究相比，大部分的方法通常直接應用預訓練的 CNN 模型（例如 VGG）來獲取新聞圖像的表達式，而本文為了要計算跨模態的相似性時，所以使用 image2sentence 將圖像先轉為文字來保持一致性。</p><h3 id=modal-independent-fake-news-detection>Modal-independent Fake News Detection</h3><p>為了在預測假新聞時正確表示新聞文本和視覺信息，我們的目標是將提取的新聞內容的文本和視覺特徵正確地映射到為假新聞的機率，並進一步映射到它們的實際標籤。</p><p>計算假新聞機率公式為</p><p>$$M_p(t,v) = 1 \dot{ } \text{softmax}(W_p(t \oplus v)+b_p) $$</p><p>其中 $1 = [1,0]^T$, $W_p \in \mathbb{R}^{2 \times 2d}$ 和 $b_p \in \mathbb{R}^{2}$ 是要被訓練的參數。</p><p>Cross-entropy-based （交叉熵） loss function:</p><p>$$L_p(\theta_t, \theta_v, \theta_p) = -\mathbb{E}_{(a,y) \sim (A,Y)}(y \log M_p(t,v) + (1-y)\log(1-M_p(t,v)))$$</p><h3 id=cross-modal-similarity-extraction>Cross-modal Similarity Extraction</h3><p>大多數的方法都是分開處理不同的模態特徵 $(t, v)$，只是將它們連接起來，並沒有觀察它們之間的關係。然而作者提到說除此之外，還可以通過評估文本信息與其視覺信息的（非）相關性來檢測新聞文章的虛假性。</p><p>假新聞創作者有時會主動使用不相關的圖像進行虛假陳述以吸引讀者的注意力，或者由於難以找到支持的非造假圖像而被迫使用它們，與提供相關文本和視覺信息的真實新聞文章相比，那些文本和圖像不相關的文章更有可能是假的。</p><p>作者這邊稍微修改餘弦相似度，定義新聞文本和視覺信息之間的相關性如下：</p><p>$$M_s(t,v) = \frac{t \cdot v + |t||v| }{2 |t||v| } $$</p><p>讓 $M_s(t,v)$ 的值為正數且 $\in [0,1]$，$M_s(t,v) \to 0$ 表示 $t, v$ 相差甚遠，$M_s(t,v) \to 1$ 表示 $t, v$ 幾乎相同。</p><p>假設從純相似性角度分析時，與文本和圖像匹配的新聞文章相比，文本和視覺信息不匹配的新聞文章更可能是假的，定義 Cross-entropy-based （交叉熵） loss function：</p><p>$$L_S(\theta_t, \theta_v) = -\mathbb{E}_{(a,y) \sim (A,Y)}(y \log (1-M_s(t,v)) + (1-y)\log M_s(t,v))$$</p><h3 id=model-integration-and-joint-learning>Model Integration and Joint Learning</h3><p>在檢測假新聞時，我們的目標是透過文本、視覺信息和它們之間的關係去正確識別假新聞。</p><p>因此定義最終 loss function：</p><p>$$L(\theta_t, \theta_v, \theta_p) = \alpha L_p(\theta_t, \theta_v, \theta_p) + \beta L_s(\theta_t, \theta_v)$$</p><p>$$L_p(\theta_t, \theta_v, \theta_p) = -\mathbb{E}_{(a,y) \sim (A,Y)}(y \log M_p(t,v) + (1-y)\log(1-M_p(t,v)))$$</p><p>$$L_S(\theta_t, \theta_v) = -\mathbb{E}_{(a,y) \sim (A,Y)}(y \log (1-M_s(t,v)) + (1-y)\log M_s(t,v))$$</p><h2 id=optimization>Optimization</h2><p><figure style=flex-grow:178;flex-basis:427px><a href=/p/fake-news-detection-safe/image-20210715201549546.png data-size=1380x774><img src=/p/fake-news-detection-safe/image-20210715201549546.png srcset="/p/fake-news-detection-safe/image-20210715201549546_huf292d83af57ff9e0d1769df8a8099f6f_238027_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715201549546_huf292d83af57ff9e0d1769df8a8099f6f_238027_1024x0_resize_box_2.png 1024w" width=1380 height=774 loading=lazy alt="SAFE Optimization Algorithm"></a><figcaption>SAFE Optimization Algorithm</figcaption></figure><figure style=flex-grow:128;flex-basis:307px><a href=/p/fake-news-detection-safe/image-20210715201639119.png data-size=2240x1746><img src=/p/fake-news-detection-safe/image-20210715201639119.png srcset="/p/fake-news-detection-safe/image-20210715201639119_huf2bbe367ef12d20ead920207669390cf_770507_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715201639119_huf2bbe367ef12d20ead920207669390cf_770507_1024x0_resize_box_2.png 1024w" width=2240 height=1746 loading=lazy alt="SAFE Update Equations"></a><figcaption>SAFE Update Equations</figcaption></figure></p><h2 id=experiments>Experiments</h2><h3 id=setup>Setup</h3><h4 id=dataset>Dataset</h4><p>FakeNewsNet</p><ul><li>PolitiFact (politifact.com) (2002.05 ~ 2018.07)<br>美國政治聲明和報告的非營利性事實核查網站。</li><li>GossipCop (gossipcop.com) (2000.07 ~ 2018.12)<br>對雜誌和報紙上發表的名人報導和娛樂故事進行事實核查。</li></ul><p><figure style=flex-grow:545;flex-basis:1309px><a href=/p/fake-news-detection-safe/image-20210715213607349.png data-size=2554x468><img src=/p/fake-news-detection-safe/image-20210715213607349.png srcset="/p/fake-news-detection-safe/image-20210715213607349_hu33b818b7ce510be2d60fd4b67ec936ca_281339_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715213607349_hu33b818b7ce510be2d60fd4b67ec936ca_281339_1024x0_resize_box_2.png 1024w" width=2554 height=468 loading=lazy alt="Data Statistics https://github.com/KaiDMML/FakeNewsNet"></a><figcaption>Data Statistics <a href=https://github.com/KaiDMML/FakeNewsNet>https://github.com/KaiDMML/FakeNewsNet</a></figcaption></figure></p><h4 id=baselines>Baselines</h4><ol><li><strong>文本 (LIWC)</strong>：廣泛接受的心理語言學詞典</li><li><strong>視覺（VGG-19）</strong>：使用微調的 VGG-19 作為基線之一</li><li><strong>多模態信息（att-RNN）：</strong>
使用帶有注意力機制 (Attention) 的 LSTM 和 VGG-19 來融合新聞文章的文本、視覺和社交平台特徵。 （為了公平，排除社交資訊）</li><li><strong>SAFE\T</strong>：不使用文本信息</li><li><strong>SAFE\V</strong>：不使用視覺信息</li><li><strong>SAFE\S</strong>：不捕捉文本和視覺特徵之間的關係（相似性）。 在這種情況下，每個新聞的特徵通過連接它們來融合</li><li><strong>SAFE\W</strong>：僅評估文本和視覺信息之間的關係。 在這種情況下，分類器與跨模態相似性提取模塊的輸出直接相連。</li></ol><h3 id=performance-analysis>Performance Analysis</h3><p><figure style=flex-grow:327;flex-basis:786px><a href=/p/fake-news-detection-safe/image-20210715214144866.png data-size=3460x1056><img src=/p/fake-news-detection-safe/image-20210715214144866.png srcset="/p/fake-news-detection-safe/image-20210715214144866_hu45946cf8b615dd721c01565f1ed4386e_910607_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715214144866_hu45946cf8b615dd721c01565f1ed4386e_910607_1024x0_resize_box_2.png 1024w" width=3460 height=1056 loading=lazy alt="Performance of Methods in Detecting Fake News"></a><figcaption>Performance of Methods in Detecting Fake News</figcaption></figure></p><ul><li>根據兩個數據集的準確度值和 F1 分數，SAFE 的表現優於所有 baseline。</li><li>在 PolitiFact 上，準確度排序：SAFE（多模態）> att-RNN（多模態）$\approx$ ￼LIWC（文本）> VGG-19（視覺）</li><li>在 GossipCop 上，準確度排序： SAFE（多模態）> VGG-19（視覺）> att-RNN（多模態）> LIWC（文本）</li></ul><h3 id=module-analysis>Module Analysis</h3><ol><li>SAFE 在所有變體中表現最佳，</li><li>使用多模態信息（SAFE\S 或 SAFE\W）比使用單模態信息（SAFE\T 或 SAFE\V）表現更好</li><li>獨立使用多模態信息（SAFE\S）或挖掘它們之間的關係（SAFE\W）來檢測假新聞兩者的準確度是可比的</li><li>文本信息（SAFE\V）比視覺信息（SAFE\T）更重要</li></ol><p><figure style=flex-grow:54;flex-basis:130px><a href=/p/fake-news-detection-safe/image-20210715214629542.png data-size=559x1030><img src=/p/fake-news-detection-safe/image-20210715214629542.png srcset="/p/fake-news-detection-safe/image-20210715214629542_hu4e1aa221f29204d884102df40b834eb0_63203_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715214629542_hu4e1aa221f29204d884102df40b834eb0_63203_1024x0_resize_box_2.png 1024w" width=559 height=1030 loading=lazy alt="Module Analysis"></a><figcaption>Module Analysis</figcaption></figure><figure style=flex-grow:113;flex-basis:272px><a href=/p/fake-news-detection-safe/image-20210715214708374.png data-size=1120x986><img src=/p/fake-news-detection-safe/image-20210715214708374.png srcset="/p/fake-news-detection-safe/image-20210715214708374_hudaf0970889790d7d6a6fc81c1fbfccf4_229991_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715214708374_hudaf0970889790d7d6a6fc81c1fbfccf4_229991_1024x0_resize_box_2.png 1024w" width=1120 height=986 loading=lazy alt="Parameter Analysis"></a><figcaption>Parameter Analysis</figcaption></figure></p><h3 id=parameter-analysis>Parameter Analysis</h3><p>α 和 β 用於分配多模態特徵 (α) 和跨模態的相似性 (β) 之間的相對重要性，準確度範圍 0.75~0.85，F1 範圍 0.8~0.9。</p><p>在兩個資料集上 α 和 β 的最佳比例也不同，這再次驗證了多模態信息和跨模態關係在預測假新聞中的重要性：</p><ul><li>PolitiFact: α : β = 0.4 : 0.6</li><li>GossipCop: α : β = 0.6 : 0.4</li></ul><h3 id=case-study>Case Study</h3><p>這邊作者提出兩個問題：</p><ul><li>是否存在任何真實世界的假新聞故事，其文本和視覺信息彼此之間沒有密切關聯？</li><li>如果存在，SAFE 能否正確識別這種無關性並進一步識別其虛假性？</li></ul><p>為此，作者瀏覽了兩個數據集中的新聞文章，並將它們的真實標籤 (ground truth) 與 SAFE 計算的相似度得分進行了比較。</p><p>一些虛構故事存在文本和視覺信息之間的差距可歸類為（但不限於）兩個原因：</p><ol><li><p>這樣的故事很難得到未經處理的圖像的支持：<br>在 Fig.5 (a) 中，實際上沒有與投票和賬單相關的圖像。在與真正親密關係的情侶 Fig.6 (c) 相比，假情侶往往很少有合影或使用拼貼畫 Fig.5 (c)。</p></li><li><p>使用<strong>有吸引力</strong>但不密切相關的圖像可以幫助增加新聞流量：<br></p><p>Fig.5 (b) 中的假新聞包括一張與死亡故事相衝突的微笑人物圖像</p></li></ol><p><figure style=flex-grow:144;flex-basis:345px><a href=/p/fake-news-detection-safe/image-20210715220237596.png data-size=1120x777><img src=/p/fake-news-detection-safe/image-20210715220237596.png srcset="/p/fake-news-detection-safe/image-20210715220237596_hu5f40eb4e99386465f077d3f034e16588_1024391_480x0_resize_box_2.png 480w, /p/fake-news-detection-safe/image-20210715220237596_hu5f40eb4e99386465f077d3f034e16588_1024391_1024x0_resize_box_2.png 1024w" width=1120 height=777 loading=lazy alt="Fake/True News Examples"></a><figcaption>Fake/True News Examples</figcaption></figure></p><p>SAFE 有助於正確評估新聞文本和視覺信息之間的關係（相似性）。</p><p>對於 Fig.5 中的假新聞，它們的相似度得分 $s$ 都很低，SAFE 正確地將它們標記為假新聞。 類似地，SAFE 為 Fig.6 中的所有真實新聞故事分配了高相似度分數 $s$ ，並將它們預測為真實新聞。</p><h2 id=conclusions>Conclusions</h2><ul><li>本文針對假新聞檢測任務提出了一種相似性感知 (similarity-aware) 的多模態方法 SAFE。</li><li>該方法提取新聞內容的文本和視覺特徵，並觀察它們之間的關係。</li><li>實驗結果表明，多模態特徵和跨模態關係（相似性）在假新聞檢測中具有相當的重要性。</li></ul><h2 id=comments>Comments</h2><ul><li>Add across-modal relationship (similarity) to detect fake news detection</li><li>Use image2sentence get image caption<ul><li>Modify cosine similarity equation</li></ul></li><li>Baseline:<ul><li>Text feature baseline only one of traditional method</li><li>Multi-modal baseline only one to compared</li></ul></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/pakdd/>pakdd</a>
<a href=/tags/fake-news-detection/>fake news detection</a>
<a href=/tags/multi-modal-analysis/>multi-modal analysis</a>
<a href=/tags/neural-networks/>neural networks</a>
<a href=/tags/representation-learning/>representation learning</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]});})</script></article><aside class=related-contents--wrapper><h2 class=section-title>Related contents</h2><div class=related-contents><div class="flex article-list--tile"><article><a href=/p/edge-cnn-human-head/><div class=article-details><h2 class=article-title>A CNN-Based Human Head Detection Algorithm Implemented on Edge AI Chip</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=chiachun2491/blog issue-term=pathname label=comments crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>function setUtterancesTheme(theme){let utterances=document.querySelector('.utterances iframe');if(utterances){utterances.contentWindow.postMessage({type:'set-theme',theme:`github-${theme}`},'https://utteranc.es');}}
addEventListener('message',event=>{if(event.origin!=='https://utteranc.es')return;setUtterancesTheme(document.documentElement.dataset.scheme)});window.addEventListener('onColorSchemeChange',(e)=>{setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2019 -
2022 Jeffery's Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=2.5.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#introduction>Introduction</a><ol><li><a href=#fake-news-detection>Fake News Detection</a></li><li><a href=#relationship-similarity-for-predicting-fake-news>Relationship (similarity) for predicting fake news</a></li><li><a href=#usuimilarity-uauware-ufuakueu-news-detection-method-safe><u>S</u>imilarity-<u>A</u>ware <u>F</u>ak<u>E</u> news detection method (SAFE)</a></li><li><a href=#contributions>Contributions</a></li></ol></li><li><a href=#methodology>Methodology</a><ol><li><a href=#problem-definition-and-key-notation>Problem Definition and Key Notation</a></li><li><a href=#feature-extraction>Feature Extraction</a><ol><li><a href=#text>Text</a></li><li><a href=#image>Image</a></li></ol></li><li><a href=#modal-independent-fake-news-detection>Modal-independent Fake News Detection</a></li><li><a href=#cross-modal-similarity-extraction>Cross-modal Similarity Extraction</a></li><li><a href=#model-integration-and-joint-learning>Model Integration and Joint Learning</a></li></ol></li><li><a href=#optimization>Optimization</a></li><li><a href=#experiments>Experiments</a><ol><li><a href=#setup>Setup</a><ol><li><a href=#dataset>Dataset</a></li><li><a href=#baselines>Baselines</a></li></ol></li><li><a href=#performance-analysis>Performance Analysis</a></li><li><a href=#module-analysis>Module Analysis</a></li><li><a href=#parameter-analysis>Parameter Analysis</a></li><li><a href=#case-study>Case Study</a></li></ol></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#comments>Comments</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous defer></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const customFont=document.createElement('link');customFont.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";customFont.type="text/css";customFont.rel="stylesheet";document.head.appendChild(customFont);}());</script></body></html>